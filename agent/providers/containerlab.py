"""Containerlab provider for container-based network labs."""

from __future__ import annotations

import asyncio
import logging
import re
from pathlib import Path

import docker
import yaml
from docker.errors import NotFound, APIError, ImageNotFound

from agent.config import settings
from agent.providers.base import (
    DeployResult,
    DestroyResult,
    NodeActionResult,
    NodeInfo,
    NodeStatus,
    Provider,
    StatusResult,
)


logger = logging.getLogger(__name__)


class MissingImagesError(Exception):
    """Raised when one or more Docker images are not available."""

    def __init__(self, missing_images: list[tuple[str, str]]):
        """Initialize with list of (node_name, image) tuples."""
        self.missing_images = missing_images
        images_str = ", ".join(f"{node}: {img}" for node, img in missing_images)
        super().__init__(f"Missing Docker images: {images_str}")


class ContainerlabProvider(Provider):
    """Provider for containerlab-based network labs.

    Uses containerlab CLI for deploy/destroy and Docker SDK for
    status queries and node control (more reliable).
    """

    def __init__(self):
        self._docker: docker.DockerClient | None = None

    @property
    def name(self) -> str:
        return "containerlab"

    @property
    def docker(self) -> docker.DockerClient:
        """Lazy-initialize Docker client."""
        if self._docker is None:
            self._docker = docker.from_env()
        return self._docker

    def _lab_prefix(self, lab_id: str) -> str:
        """Get container name prefix for a lab.

        Containerlab names containers as: clab-{topology_name}-{node_name}
        We use lab_id as topology name for uniqueness.
        """
        # Sanitize lab_id for use in container names
        safe_id = re.sub(r'[^a-zA-Z0-9_-]', '', lab_id)[:20]
        return f"clab-{safe_id}"

    def _topology_path(self, workspace: Path) -> Path:
        """Get path to topology file in workspace."""
        return workspace / "topology.clab.yml"

    def _validate_images(self, topology_yaml: str) -> list[tuple[str, str]]:
        """Validate that all Docker images in the topology exist.

        Args:
            topology_yaml: The topology YAML content

        Returns:
            List of (node_name, image) tuples for missing images

        This performs pre-deployment validation to catch missing images early
        and provide clear error messages to users.
        """
        missing_images: list[tuple[str, str]] = []

        try:
            topo = yaml.safe_load(topology_yaml)
            if not topo:
                return missing_images

            # Handle both wrapped and flat topology formats
            nodes = topo.get("topology", {}).get("nodes", {})
            if not nodes:
                nodes = topo.get("nodes", {})

            if not isinstance(nodes, dict):
                return missing_images

            for node_name, node_config in nodes.items():
                if not isinstance(node_config, dict):
                    continue

                image = node_config.get("image")
                if not image:
                    continue

                # Check if the image exists locally
                try:
                    self.docker.images.get(image)
                except ImageNotFound:
                    missing_images.append((node_name, image))
                except APIError as e:
                    logger.warning(f"Error checking image {image}: {e}")

        except Exception as e:
            logger.warning(f"Failed to validate images: {e}")

        return missing_images

    def _format_missing_images_error(self, missing_images: list[tuple[str, str]]) -> str:
        """Format a user-friendly error message for missing images.

        Args:
            missing_images: List of (node_name, image) tuples

        Returns:
            Formatted error message with guidance
        """
        lines = [
            "=" * 60,
            "DEPLOYMENT FAILED: Missing Docker Images",
            "=" * 60,
            "",
            "The following nodes require Docker images that are not available:",
            "",
        ]

        for node_name, image in missing_images:
            lines.append(f"  â€¢ Node '{node_name}' requires image: {image}")

        lines.extend([
            "",
            "To resolve this issue:",
            "  1. Upload the required images via the Images page in the GUI",
            "  2. Or manually import the images using: docker load -i <image-file>",
            "  3. Or pull images from a registry: docker pull <image-name>",
            "",
            "For cEOS images, download from arista.com and upload via the GUI.",
            "=" * 60,
        ])

        return "\n".join(lines)

    def _build_verbose_error_output(
        self,
        title: str,
        user_error: str,
        stdout: str,
        stderr: str,
        returncode: int,
    ) -> str:
        """Build verbose error output for task log.

        Args:
            title: Error title (e.g., "DEPLOYMENT FAILED")
            user_error: User-friendly error message
            stdout: Standard output from command
            stderr: Standard error from command
            returncode: Exit code from command

        Returns:
            Formatted verbose error output
        """
        lines = [
            "=" * 60,
            title,
            "=" * 60,
            "",
            f"Error: {user_error}",
            "",
            f"Exit code: {returncode}",
            "",
        ]

        if stdout and stdout.strip():
            lines.extend([
                "-" * 40,
                "STDOUT:",
                "-" * 40,
                stdout.strip(),
                "",
            ])

        if stderr and stderr.strip():
            lines.extend([
                "-" * 40,
                "STDERR:",
                "-" * 40,
                stderr.strip(),
                "",
            ])

        lines.append("=" * 60)
        return "\n".join(lines)

    def _parse_deploy_error(self, stdout: str, stderr: str, returncode: int) -> str:
        """Parse containerlab output to provide user-friendly error messages.

        Args:
            stdout: Standard output from containerlab
            stderr: Standard error from containerlab
            returncode: Exit code from containerlab

        Returns:
            User-friendly error message
        """
        combined_output = f"{stdout}\n{stderr}".lower()

        # Check for common error patterns
        if "image" in combined_output and ("not found" in combined_output or "no such image" in combined_output):
            # Extract image name if possible
            match = re.search(r'image["\s:]+([^\s"]+)["\s]*(not found|does not exist)', combined_output, re.IGNORECASE)
            if match:
                image_name = match.group(1)
                return (
                    f"Docker image '{image_name}' not found.\n"
                    f"Please upload the image via the Images page or import it manually."
                )
            return (
                "One or more Docker images not found.\n"
                "Please check that all required images are available."
            )

        if "permission denied" in combined_output:
            return (
                "Permission denied during deployment.\n"
                "The agent may not have sufficient privileges to create containers."
            )

        if "network" in combined_output and ("already exists" in combined_output or "in use" in combined_output):
            return (
                "Network conflict detected.\n"
                "A network with the same name already exists. Try destroying the lab first."
            )

        if "port" in combined_output and "already" in combined_output and ("bound" in combined_output or "use" in combined_output):
            return (
                "Port conflict detected.\n"
                "A required port is already in use by another container or service."
            )

        # Default error message
        return f"containerlab deploy failed with exit code {returncode}"

    def _ensure_ceos_flash_dirs(self, topology_yaml: str, workspace: Path) -> None:
        """Ensure flash directories exist for cEOS nodes before deployment.

        cEOS nodes require a persistent flash directory mounted to /mnt/flash
        for configuration persistence. This method parses the topology YAML
        and creates the necessary directories.

        The binds in topology.py specify paths like:
        {workspace}/configs/{node_name}/flash:/mnt/flash
        """
        try:
            topo = yaml.safe_load(topology_yaml)
            if not topo:
                return

            # Handle both wrapped and flat topology formats
            nodes = topo.get("topology", {}).get("nodes", {})
            if not nodes:
                nodes = topo.get("nodes", {})

            if not isinstance(nodes, dict):
                return

            for node_name, node_config in nodes.items():
                if not isinstance(node_config, dict):
                    continue

                # Check if this is a cEOS node
                kind = node_config.get("kind", "")
                if kind != "ceos":
                    continue

                # Create the flash directory for this node
                flash_dir = workspace / "configs" / node_name / "flash"
                flash_dir.mkdir(parents=True, exist_ok=True)
                logger.debug(f"Created cEOS flash directory: {flash_dir}")

        except Exception as e:
            logger.warning(f"Failed to ensure cEOS flash directories: {e}")

    def _strip_archetype_fields(self, topology_yaml: str, lab_id: str = "", workspace: Path | None = None) -> str:
        """Strip Archetype-specific fields and convert to containerlab format.

        The 'host' field is used by Archetype for multi-host placement but is not
        a valid containerlab field.

        Also wraps flat topology in containerlab format if needed:
        - Input: {nodes: {...}, links: [...]}
        - Output: {name: lab-id, topology: {nodes: {...}, links: [...]}}

        Additionally rewrites bind paths to use the agent's workspace.
        """
        try:
            topo = yaml.safe_load(topology_yaml)
            if not topo:
                return topology_yaml

            def rewrite_binds(node_config: dict) -> None:
                """Rewrite bind paths to use agent workspace."""
                if not workspace or "binds" not in node_config:
                    return
                new_binds = []
                for bind in node_config.get("binds", []):
                    if ":" in bind:
                        host_path, container_path = bind.split(":", 1)
                        # Rewrite paths containing /configs/ to use agent workspace
                        if "/configs/" in host_path:
                            # Extract the relative part (configs/node_name/flash)
                            configs_idx = host_path.find("/configs/")
                            relative_path = host_path[configs_idx + 1:]  # Remove leading /
                            new_host_path = str(workspace / relative_path)
                            new_binds.append(f"{new_host_path}:{container_path}")
                        else:
                            new_binds.append(bind)
                    else:
                        new_binds.append(bind)
                node_config["binds"] = new_binds

            # Check if already in containerlab format
            if "topology" in topo:
                # Already wrapped - strip custom fields and rewrite binds
                # Remove _external_networks (used by agent for VLAN setup, not valid for clab)
                if "_external_networks" in topo:
                    del topo["_external_networks"]
                nodes = topo.get("topology", {}).get("nodes", {})
                if isinstance(nodes, dict):
                    for node_name, node_config in nodes.items():
                        if isinstance(node_config, dict):
                            if "host" in node_config:
                                del node_config["host"]
                            rewrite_binds(node_config)
                return yaml.dump(topo, default_flow_style=False)

            # Flat format - need to wrap for containerlab
            nodes = topo.get("nodes", {})
            links = topo.get("links", [])
            defaults = topo.get("defaults", {})

            # Strip 'host' field from nodes and rewrite binds
            if isinstance(nodes, dict):
                for node_name, node_config in nodes.items():
                    if isinstance(node_config, dict):
                        if "host" in node_config:
                            del node_config["host"]
                        rewrite_binds(node_config)

            # Build containerlab format
            import re
            safe_lab_id = re.sub(r'[^a-zA-Z0-9_-]', '', lab_id)[:20] or "lab"

            clab_topo = {
                "name": safe_lab_id,
                "topology": {
                    "nodes": nodes,
                }
            }

            # Only add links if present
            if links:
                clab_topo["topology"]["links"] = links

            # Add defaults if present
            if defaults:
                clab_topo["topology"]["defaults"] = defaults

            return yaml.dump(clab_topo, default_flow_style=False)
        except Exception as e:
            logger.warning(f"Failed to process topology: {e}")
            return topology_yaml

    async def _run_clab(
        self,
        args: list[str],
        workspace: Path,
        timeout: float | None = None,
    ) -> tuple[int, str, str]:
        """Run containerlab command asynchronously with timeout.

        Args:
            args: Arguments to pass to clab command
            workspace: Working directory for the command
            timeout: Maximum time in seconds to wait for command (default: settings.deploy_timeout)

        Returns:
            Tuple of (return_code, stdout, stderr)

        Raises:
            TimeoutError: If command exceeds timeout
        """
        if timeout is None:
            timeout = settings.deploy_timeout

        cmd = ["clab"] + args
        logger.debug(f"Running: clab {' '.join(args)} (timeout={timeout}s)")

        process = await asyncio.create_subprocess_exec(
            *cmd,
            cwd=str(workspace),
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )

        try:
            stdout, stderr = await asyncio.wait_for(
                process.communicate(),
                timeout=timeout,
            )
            return (
                process.returncode or 0,
                stdout.decode(errors="replace"),
                stderr.decode(errors="replace"),
            )
        except asyncio.TimeoutError:
            logger.error(f"Command timed out after {timeout}s: clab {' '.join(args)}")
            # Kill the hung process
            try:
                process.kill()
                await process.wait()
            except Exception as e:
                logger.warning(f"Error killing timed-out process: {e}")
            raise TimeoutError(f"containerlab command timed out after {timeout}s: clab {' '.join(args)}")

    def _is_ceos_container(self, container) -> bool:
        """Check if a container is a cEOS node based on containerlab labels."""
        try:
            kind = container.labels.get("clab-node-kind", "")
            return kind == "ceos"
        except Exception:
            return False

    async def _extract_node_config(
        self,
        container_name: str,
        workspace: Path,
        node_name: str,
    ) -> bool:
        """Extract running-config from a cEOS node and save to workspace.

        Args:
            container_name: Docker container name
            workspace: Lab workspace directory
            node_name: Node name for config file naming

        Returns:
            True if config was extracted successfully, False otherwise
        """
        content = await self._extract_node_config_content(container_name, workspace, node_name)
        return content is not None

    async def _extract_node_config_content(
        self,
        container_name: str,
        workspace: Path,
        node_name: str,
    ) -> str | None:
        """Extract running-config from a cEOS node, save to workspace, and return content.

        Args:
            container_name: Docker container name
            workspace: Lab workspace directory
            node_name: Node name for config file naming

        Returns:
            Config content if extracted successfully, None otherwise
        """
        try:
            container = self.docker.containers.get(container_name)

            # Only extract from running containers
            if container.status.lower() != "running":
                logger.debug(f"Skipping config extraction for {container_name}: container not running")
                return None

            # Only extract from cEOS nodes
            if not self._is_ceos_container(container):
                logger.debug(f"Skipping config extraction for {container_name}: not a cEOS node")
                return None

            logger.info(f"Extracting running-config from {container_name}")

            # Run 'Cli -p 15 -c "show running-config"' to get the config
            # The -p 15 flag enables privileged mode (level 15) required for show running-config
            exit_code, output = container.exec_run(
                cmd=['Cli', '-p', '15', '-c', 'show running-config'],
                demux=True,
            )

            if exit_code != 0:
                stderr = output[1].decode(errors="replace") if output[1] else ""
                logger.warning(f"Failed to extract config from {container_name}: exit code {exit_code}, stderr: {stderr}")
                return None

            stdout = output[0].decode(errors="replace") if output[0] else ""

            if not stdout.strip():
                logger.warning(f"Empty config extracted from {container_name}")
                return None

            # Save config to workspace/configs/{node_name}/startup-config
            config_dir = workspace / "configs" / node_name
            config_dir.mkdir(parents=True, exist_ok=True)
            config_path = config_dir / "startup-config"

            config_path.write_text(stdout, encoding="utf-8")
            logger.info(f"Saved running-config to {config_path}")

            return stdout

        except NotFound:
            logger.debug(f"Container {container_name} not found for config extraction")
            return None
        except APIError as e:
            logger.warning(f"Docker API error extracting config from {container_name}: {e}")
            return None
        except Exception as e:
            logger.warning(f"Error extracting config from {container_name}: {e}")
            return None

    def _get_container_status(self, container) -> NodeStatus:
        """Map Docker container status to NodeStatus."""
        status = container.status.lower()
        if status == "running":
            return NodeStatus.RUNNING
        elif status == "created":
            return NodeStatus.PENDING
        elif status in ("exited", "dead"):
            return NodeStatus.STOPPED
        elif status == "paused":
            return NodeStatus.STOPPED
        elif status == "restarting":
            return NodeStatus.STARTING
        else:
            return NodeStatus.UNKNOWN

    def _get_container_ips(self, container) -> list[str]:
        """Extract IP addresses from container."""
        ips = []
        try:
            networks = container.attrs.get("NetworkSettings", {}).get("Networks", {})
            for net_name, net_info in networks.items():
                if net_info.get("IPAddress"):
                    ips.append(net_info["IPAddress"])
        except Exception:
            pass
        return ips

    def _node_from_container(self, container, prefix: str) -> NodeInfo | None:
        """Convert Docker container to NodeInfo."""
        name = container.name

        # Extract node name from container name (clab-{lab}-{node})
        if not name.startswith(prefix + "-"):
            return None

        node_name = name[len(prefix) + 1:]

        return NodeInfo(
            name=node_name,
            status=self._get_container_status(container),
            container_id=container.short_id,
            image=container.image.tags[0] if container.image.tags else str(container.image.id)[:12],
            ip_addresses=self._get_container_ips(container),
        )

    async def _pre_deploy_cleanup(self, lab_id: str, workspace: Path) -> list[str]:
        """Clean up orphaned or unhealthy containers before deployment.

        This prevents --reconfigure from trying to reconfigure containers in bad states.

        Returns:
            List of container names that were removed
        """
        prefix = self._lab_prefix(lab_id)
        removed = []

        try:
            containers = self.docker.containers.list(
                all=True,
                filters={"name": prefix},
            )

            for container in containers:
                status = container.status.lower()
                # Remove containers that are in bad states
                # Keep running containers (--reconfigure will handle them)
                if status in ("exited", "dead", "created", "removing"):
                    logger.info(f"Pre-deploy cleanup: removing {status} container {container.name}")
                    try:
                        container.remove(force=True)
                        removed.append(container.name)
                    except Exception as e:
                        logger.warning(f"Failed to remove container {container.name}: {e}")

            if removed:
                logger.info(f"Pre-deploy cleanup removed {len(removed)} containers")

        except Exception as e:
            logger.warning(f"Pre-deploy cleanup error: {e}")

        return removed

    async def _cleanup_failed_deploy(self, lab_id: str, workspace: Path) -> None:
        """Clean up any containers created during a failed deployment."""
        prefix = self._lab_prefix(lab_id)
        logger.info(f"Cleaning up containers for failed deployment: {prefix}")

        try:
            containers = self.docker.containers.list(
                all=True,
                filters={"name": prefix},
            )

            for container in containers:
                try:
                    logger.info(f"Removing container: {container.name}")
                    container.remove(force=True)
                except Exception as e:
                    logger.warning(f"Failed to remove container {container.name}: {e}")

            # Also try containerlab destroy to clean up any networks/bridges
            topo_path = self._topology_path(workspace)
            if topo_path.exists():
                try:
                    await self._run_clab(
                        ["destroy", "-t", str(topo_path), "--cleanup"],
                        workspace,
                        timeout=settings.destroy_timeout,
                    )
                except TimeoutError:
                    logger.warning("clab destroy during cleanup timed out")
                except Exception as e:
                    logger.warning(f"clab destroy during cleanup failed: {e}")

        except Exception as e:
            logger.error(f"Error during deployment cleanup: {e}")

    async def deploy(
        self,
        lab_id: str,
        topology_yaml: str,
        workspace: Path,
        agent_id: str | None = None,
    ) -> DeployResult:
        """Deploy a containerlab topology.

        Uses a two-phase approach:
        1. Pre-deploy validation (check images exist)
        2. Pre-deploy cleanup to remove orphaned/unhealthy containers
        3. Deploy with --reconfigure (works for running containers)
        4. Fallback to fresh deploy if --reconfigure fails

        If deployment fails, automatically cleans up any partially created resources.
        """
        # Ensure workspace exists
        workspace.mkdir(parents=True, exist_ok=True)

        # Strip Archetype-specific fields and convert to containerlab format
        # Also rewrites bind paths to use the agent's workspace
        clean_topology = self._strip_archetype_fields(topology_yaml, lab_id, workspace)

        # Pre-deployment validation: check that all required images exist
        logger.info(f"Validating Docker images for lab {lab_id}...")
        missing_images = self._validate_images(clean_topology)
        if missing_images:
            error_msg = self._format_missing_images_error(missing_images)
            logger.error(f"Image validation failed for lab {lab_id}: {len(missing_images)} missing images")
            for node_name, image in missing_images:
                logger.error(f"  Missing: {image} (required by node '{node_name}')")
            return DeployResult(
                success=False,
                stdout="",
                stderr=error_msg,
                error=f"Missing {len(missing_images)} Docker image(s). See task log for details.",
            )
        logger.info(f"Image validation passed for lab {lab_id}")

        # Ensure flash directories exist for cEOS nodes (required for config persistence)
        self._ensure_ceos_flash_dirs(clean_topology, workspace)

        # Set up external network VLAN interfaces before containerlab deploy
        try:
            from agent.network.vlan import setup_external_networks
            created_vlans = await setup_external_networks(lab_id, topology_yaml, agent_id)
            if created_vlans:
                logger.info(f"Created {len(created_vlans)} VLAN interfaces for external networks")
        except Exception as e:
            logger.warning(f"Failed to set up external network VLANs: {e}")
            # Continue with deploy - external networks are optional

        # Write topology file
        topo_path = self._topology_path(workspace)
        topo_path.write_text(clean_topology, encoding="utf-8")

        logger.info(f"Deploying lab {lab_id} from {topo_path}")

        # Pre-deploy cleanup: remove containers in bad states
        await self._pre_deploy_cleanup(lab_id, workspace)

        # First attempt: deploy with --reconfigure
        logger.info(f"Starting containerlab deploy for lab {lab_id}...")
        try:
            returncode, stdout, stderr = await self._run_clab(
                ["deploy", "-t", str(topo_path), "--reconfigure"],
                workspace,
            )
        except TimeoutError as e:
            logger.error(f"Deploy timed out for lab {lab_id}: {e}")
            await self._cleanup_failed_deploy(lab_id, workspace)

            timeout_error = (
                f"Deployment timed out after {settings.deploy_timeout} seconds.\n"
                "This may indicate that containers are taking too long to start.\n"
                "Check that the host has sufficient resources (CPU, memory)."
            )
            verbose_output = self._build_verbose_error_output(
                "DEPLOYMENT TIMEOUT",
                timeout_error,
                "",
                str(e),
                -1,
            )

            return DeployResult(
                success=False,
                stdout="",
                stderr=verbose_output,
                error=timeout_error,
            )

        if returncode != 0:
            logger.warning(f"Deploy with --reconfigure failed for lab {lab_id}: exit code {returncode}")
            logger.info(f"Attempting fallback: destroy + fresh deploy for lab {lab_id}")

            # Fallback: destroy and try fresh deploy
            try:
                # Full cleanup
                await self._cleanup_failed_deploy(lab_id, workspace)

                # Fresh deploy without --reconfigure
                returncode, stdout, stderr = await self._run_clab(
                    ["deploy", "-t", str(topo_path)],
                    workspace,
                )
            except TimeoutError as e:
                logger.error(f"Fresh deploy timed out for lab {lab_id}: {e}")
                await self._cleanup_failed_deploy(lab_id, workspace)

                timeout_error = (
                    f"Deployment timed out after {settings.deploy_timeout} seconds.\n"
                    "This may indicate that containers are taking too long to start.\n"
                    "Check that the host has sufficient resources (CPU, memory)."
                )
                verbose_output = self._build_verbose_error_output(
                    "DEPLOYMENT TIMEOUT",
                    timeout_error,
                    stdout,
                    stderr,
                    -1,
                )

                return DeployResult(
                    success=False,
                    stdout=stdout,
                    stderr=verbose_output,
                    error=timeout_error,
                )

            if returncode != 0:
                logger.error(f"Fresh deploy also failed for lab {lab_id}: exit code {returncode}")
                logger.error(f"Deploy stdout:\n{stdout}")
                logger.error(f"Deploy stderr:\n{stderr}")
                await self._cleanup_failed_deploy(lab_id, workspace)

                # Parse error to provide user-friendly message
                user_error = self._parse_deploy_error(stdout, stderr, returncode)

                # Build verbose error output for task log
                verbose_stderr = self._build_verbose_error_output(
                    "DEPLOYMENT FAILED",
                    user_error,
                    stdout,
                    stderr,
                    returncode,
                )

                return DeployResult(
                    success=False,
                    stdout=stdout,
                    stderr=verbose_stderr,
                    error=user_error,
                )

        # Get deployed node info
        status_result = await self.status(lab_id, workspace)

        # Verify all nodes are running
        failed_nodes = [n for n in status_result.nodes if n.status != NodeStatus.RUNNING]
        if failed_nodes:
            failed_names = ", ".join(n.name for n in failed_nodes)
            logger.warning(f"Some nodes not running after deploy: {failed_names}")
            # Don't fail the whole deploy, but include warning in output
            stdout += f"\n\nWarning: Some nodes may not be fully running: {failed_names}"

        logger.info(f"Deploy completed for lab {lab_id}: {len(status_result.nodes)} nodes")

        return DeployResult(
            success=True,
            nodes=status_result.nodes,
            stdout=stdout,
            stderr=stderr,
        )

    async def _extract_all_ceos_configs(self, lab_id: str, workspace: Path) -> list[tuple[str, str]]:
        """Extract configs from all running cEOS containers for a lab.

        Args:
            lab_id: Lab identifier
            workspace: Lab workspace directory

        Returns:
            List of (node_name, config_content) tuples for successfully extracted configs
        """
        prefix = self._lab_prefix(lab_id)
        extracted_configs: list[tuple[str, str]] = []

        try:
            containers = self.docker.containers.list(
                all=True,
                filters={"name": prefix},
            )

            for container in containers:
                # Skip non-running containers
                if container.status.lower() != "running":
                    continue

                # Skip non-cEOS containers
                if not self._is_ceos_container(container):
                    continue

                # Extract node name from container name
                name = container.name
                if not name.startswith(prefix + "-"):
                    continue
                node_name = name[len(prefix) + 1:]

                # Extract config
                config_content = await self._extract_node_config_content(container.name, workspace, node_name)
                if config_content:
                    extracted_configs.append((node_name, config_content))

        except Exception as e:
            logger.warning(f"Error extracting cEOS configs for lab {lab_id}: {e}")

        if extracted_configs:
            logger.info(f"Extracted {len(extracted_configs)} cEOS configs")

        return extracted_configs

    async def destroy(
        self,
        lab_id: str,
        workspace: Path,
    ) -> DestroyResult:
        """Destroy a containerlab topology."""
        topo_path = self._topology_path(workspace)

        # Extract configs from all running cEOS containers before destroy
        await self._extract_all_ceos_configs(lab_id, workspace)

        if not topo_path.exists():
            # Try to destroy by prefix if topology file is missing
            prefix = self._lab_prefix(lab_id)
            try:
                containers = self.docker.containers.list(
                    all=True,
                    filters={"name": prefix},
                )
                for container in containers:
                    try:
                        container.remove(force=True)
                    except Exception:
                        pass

                # Clean up external network VLAN interfaces
                try:
                    from agent.network.vlan import cleanup_external_networks
                    deleted_vlans = await cleanup_external_networks(lab_id)
                    if deleted_vlans:
                        logger.info(f"Cleaned up {len(deleted_vlans)} VLAN interfaces")
                except Exception as e:
                    logger.warning(f"Failed to clean up external network VLANs: {e}")

                return DestroyResult(
                    success=True,
                    stdout=f"Removed {len(containers)} containers by prefix",
                )
            except Exception as e:
                return DestroyResult(
                    success=False,
                    error=f"Failed to destroy by prefix: {e}",
                )

        # Run containerlab destroy
        returncode, stdout, stderr = await self._run_clab(
            ["destroy", "-t", str(topo_path), "--cleanup"],
            workspace,
            timeout=settings.destroy_timeout,
        )

        # Clean up external network VLAN interfaces after containerlab destroy
        try:
            from agent.network.vlan import cleanup_external_networks
            deleted_vlans = await cleanup_external_networks(lab_id)
            if deleted_vlans:
                logger.info(f"Cleaned up {len(deleted_vlans)} VLAN interfaces")
                stdout += f"\nCleaned up {len(deleted_vlans)} VLAN interfaces"
        except Exception as e:
            logger.warning(f"Failed to clean up external network VLANs: {e}")

        if returncode != 0:
            logger.error(f"Destroy failed for lab {lab_id}: exit code {returncode}")
            logger.error(f"Destroy stdout:\n{stdout}")
            logger.error(f"Destroy stderr:\n{stderr}")

            verbose_stderr = self._build_verbose_error_output(
                "DESTROY FAILED",
                f"containerlab destroy failed with exit code {returncode}",
                stdout,
                stderr,
                returncode,
            )

            return DestroyResult(
                success=False,
                stdout=stdout,
                stderr=verbose_stderr,
                error=f"containerlab destroy failed with exit code {returncode}",
            )

        logger.info(f"Destroy completed for lab {lab_id}")
        return DestroyResult(
            success=True,
            stdout=stdout,
            stderr=stderr,
        )

    async def status(
        self,
        lab_id: str,
        workspace: Path,
    ) -> StatusResult:
        """Get status of all nodes using Docker SDK."""
        prefix = self._lab_prefix(lab_id)
        nodes: list[NodeInfo] = []

        try:
            # Find all containers with our lab prefix
            containers = self.docker.containers.list(
                all=True,
                filters={"name": prefix},
            )

            for container in containers:
                node = self._node_from_container(container, prefix)
                if node:
                    nodes.append(node)

            return StatusResult(
                lab_exists=len(nodes) > 0,
                nodes=nodes,
            )

        except Exception as e:
            return StatusResult(
                lab_exists=False,
                error=str(e),
            )

    async def start_node(
        self,
        lab_id: str,
        node_name: str,
        workspace: Path,
    ) -> NodeActionResult:
        """Start a specific node using Docker SDK."""
        prefix = self._lab_prefix(lab_id)
        container_name = f"{prefix}-{node_name}"

        try:
            container = self.docker.containers.get(container_name)
            container.start()

            # Wait briefly for container to start
            await asyncio.sleep(1)

            # Refresh container state
            container.reload()

            return NodeActionResult(
                success=True,
                node_name=node_name,
                new_status=self._get_container_status(container),
                stdout=f"Started container {container_name}",
            )

        except NotFound:
            return NodeActionResult(
                success=False,
                node_name=node_name,
                error=f"Container {container_name} not found",
            )
        except APIError as e:
            return NodeActionResult(
                success=False,
                node_name=node_name,
                error=f"Docker API error: {e}",
            )
        except Exception as e:
            return NodeActionResult(
                success=False,
                node_name=node_name,
                error=str(e),
            )

    async def stop_node(
        self,
        lab_id: str,
        node_name: str,
        workspace: Path,
    ) -> NodeActionResult:
        """Stop a specific node using Docker SDK."""
        prefix = self._lab_prefix(lab_id)
        container_name = f"{prefix}-{node_name}"

        try:
            container = self.docker.containers.get(container_name)

            # Extract config before stopping (for cEOS nodes)
            await self._extract_node_config(container_name, workspace, node_name)

            container.stop(timeout=settings.container_stop_timeout)

            # Refresh container state
            container.reload()

            return NodeActionResult(
                success=True,
                node_name=node_name,
                new_status=self._get_container_status(container),
                stdout=f"Stopped container {container_name}",
            )

        except NotFound:
            return NodeActionResult(
                success=False,
                node_name=node_name,
                error=f"Container {container_name} not found",
            )
        except APIError as e:
            return NodeActionResult(
                success=False,
                node_name=node_name,
                error=f"Docker API error: {e}",
            )
        except Exception as e:
            return NodeActionResult(
                success=False,
                node_name=node_name,
                error=str(e),
            )

    async def get_console_command(
        self,
        lab_id: str,
        node_name: str,
        workspace: Path,
    ) -> list[str] | None:
        """Get docker exec command for console access."""
        prefix = self._lab_prefix(lab_id)
        container_name = f"{prefix}-{node_name}"

        try:
            container = self.docker.containers.get(container_name)
            if container.status != "running":
                return None

            # Return docker exec command
            # The actual PTY handling is done in the console module
            return ["docker", "exec", "-it", container_name, "/bin/sh"]

        except NotFound:
            return None
        except Exception:
            return None

    def get_container_name(self, lab_id: str, node_name: str) -> str:
        """Get the Docker container name for a node."""
        prefix = self._lab_prefix(lab_id)
        return f"{prefix}-{node_name}"

    async def discover_labs(self) -> dict[str, list[NodeInfo]]:
        """Discover all running containerlab labs and their nodes.

        Returns a dict mapping lab_id to list of NodeInfo for that lab.
        Used for reconciliation after agent/controller restart.
        """
        discovered: dict[str, list[NodeInfo]] = {}

        try:
            # Find all containerlab containers (they all start with "clab-")
            containers = self.docker.containers.list(
                all=True,
                filters={"name": "clab-"},
            )

            for container in containers:
                name = container.name
                # Parse container name: clab-{lab_id}-{node_name}
                if not name.startswith("clab-"):
                    continue

                parts = name[5:].split("-", 1)  # Remove "clab-" prefix
                if len(parts) < 2:
                    continue

                lab_id = parts[0]
                node_name = parts[1]

                node_info = NodeInfo(
                    name=node_name,
                    status=self._get_container_status(container),
                    container_id=container.short_id,
                    image=container.image.tags[0] if container.image.tags else str(container.image.id)[:12],
                    ip_addresses=self._get_container_ips(container),
                )

                if lab_id not in discovered:
                    discovered[lab_id] = []
                discovered[lab_id].append(node_info)

            logger.info(f"Discovered {len(discovered)} labs with running containers")

        except Exception as e:
            logger.error(f"Error discovering labs: {e}")

        return discovered

    async def cleanup_orphan_containers(self, valid_lab_ids: set[str]) -> list[str]:
        """Remove containers for labs that no longer exist in the database.

        Args:
            valid_lab_ids: Set of lab IDs that are valid (exist in DB)

        Returns:
            List of container names that were removed
        """
        removed: list[str] = []

        try:
            containers = self.docker.containers.list(
                all=True,
                filters={"name": "clab-"},
            )

            for container in containers:
                name = container.name
                if not name.startswith("clab-"):
                    continue

                parts = name[5:].split("-", 1)
                if len(parts) < 2:
                    continue

                lab_id = parts[0]

                if lab_id not in valid_lab_ids:
                    logger.info(f"Removing orphan container: {name}")
                    try:
                        container.remove(force=True)
                        removed.append(name)
                    except Exception as e:
                        logger.warning(f"Failed to remove orphan container {name}: {e}")

            if removed:
                logger.info(f"Cleaned up {len(removed)} orphan containers")

        except Exception as e:
            logger.error(f"Error cleaning up orphan containers: {e}")

        return removed
